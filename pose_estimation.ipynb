{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPw63VjEmADVmQJ7/v+e+ZP"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"kBdVeu7g6OcZ","colab":{"base_uri":"https://localhost:8080/","height":262},"executionInfo":{"status":"error","timestamp":1703835191916,"user_tz":-330,"elapsed":3789,"user":{"displayName":"Arunkumar DURAISAMY","userId":"08300568961865271195"}},"outputId":"1bd3cd7c-1498-4660-9816-9b451305d656"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]},{"output_type":"error","ename":"error","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-2015c55d65a5>\u001b[0m in \u001b[0;36m<cell line: 54>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;31m############## CALIBRATION #######################################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m \u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcameraMatrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrvecs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtvecs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalibrateCamera\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjpoints\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimgpoints\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframeSize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Camera Matrix\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcameraMatrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31merror\u001b[0m: OpenCV(4.8.0) /io/opencv/modules/calib3d/src/calibration.cpp:3752: error: (-215:Assertion failed) nimages > 0 in function 'calibrateCameraRO'\n"]}],"source":["import numpy as np\n","import cv2\n","\n","def aruco_display(corners,ids,rejected,image):\n","\tif(len(corners)>0):\n","\t\tids=ids.flatten()\n","\t\tfor(markerCorner,markerID) in zip(corners,ids):\n","\t\t\tcorners=markerCorner.reshape((4,2))\n","\t\t\t(topLeft,topRight,bottomRight,bottomLeft)=corners\n","\t\t\ttopRight=(int(topRight[0]),int(topRight[1]))\n","\t\t\ttopLeft=(int(topLeft[0]),int(topLeft[1]))\n","\t\t\tbottomRight=(int(bottomRight[0]),int(bottomRight[1]))\n","\t\t\tbottomLeft=(int(bottomLeft[0]),int(bottomLeft[1]))\n","\t\t\tcv2.line(image,topLeft,topRight,(0,255,0),2)\n","\t\t\tcv2.line(image,topRight,bottomRight,(0,255,0),2)\n","\t\t\tcv2.line(image,bottomRight,bottomLeft,(0,255,0),2)\n","\t\t\tcv2.line(image,bottomLeft,topLeft,(0,255,0),2)\n","\t\t\tcX=int((topLeft[0]+bottomRight[0]+topRight[0]+bottomLeft[0])/4)\n","\t\t\tcY=int((topLeft[1]+bottomLeft[1]+bottomRight[1]+topRight[1])/4)\n","\t\t\tcv2.circle(image,(cX,cY),4,(0,0,255),-1)\n","\t\t\tprint(str(image.shape[0])+'x'+str(image.shape[1]))\n","\t\t\tprint(\"[Inference] Aruco marker ID: {}\".format(markerID))\n","\n","\treturn image\n","\n","arucoDict=cv2.aruco.Dictionary_get(cv2.aruco.DICT_4X4_50)\n","arucoParams=cv2.aruco.DetectorParameters_create()\n","img=cv2.imread(r\"C:\\Users\\aravi\\OneDrive\\Desktop\\EEA_OpenCV_drone\\marker_0.png\")\n","h,w,_=img.shape\n","width=1000\n","height=int(width*(h/w))\n","img=cv2.resize(img,(width,height),interpolation=cv2.INTER_CUBIC)\n","corners,ids,rejected=cv2.aruco.detectMarkers(img,arucoDict,parameters=arucoParams)\n","print(ids)\n","detected_markers=aruco_display(corners,ids,rejected,img)\n","cv2.imshow(\"Image\",detected_markers)\n","cv2.waitKey(0)\n","cv2.destroyAllWindows()\n","\n","def pose_estimation(frame, aruco_dict_type, matrix_coefficients, distortion_coefficients):\n","\n","\tgray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n","\tarucoDict=cv2.aruco.Dictionary_get(cv2.aruco.DICT_4X4_50)\n","\tarucoParams=cv2.aruco.DetectorParameters_create()\n","\tcorners, ids, rejected_img_points=cv2.aruco.detectMarkers(gray,arucoDict,parameters=arucoParams)\n","\n","\n","\tif len(corners) > 0:\n","\t\tfor i in range(0, len(ids)):\n","\t\t\trvec, tvec, markerPoints = cv2.aruco.estimatePoseSingleMarkers(corners[i], 50, matrix_coefficients,distortion_coefficients)\n","\t\t\tcv2.aruco.drawDetectedMarkers(frame, corners)\n","\t\t\tcv2.drawFrameAxes(frame, matrix_coefficients, distortion_coefficients, rvec, tvec, 5)\n","\t\t\tprint(tvec)\n","\treturn frame\n","\n","cap=cv2.VideoCapture(0)\n","\n","cap.set(cv2.CAP_PROP_FRAME_WIDTH,1280)\n","cap.set(cv2.CAP_PROP_FRAME_HEIGHT,720)\n","\n","while cap.isOpened():\n","\tret,img=cap.read()\n","\th,w,_=img.shape\n","\twidth=1000\n","\theight=int(width*(h/w))\n","\timg=cv2.resize(img,(width,height),interpolation=cv2.INTER_CUBIC)\n","\tintrinsic_camera = np.array(((207.66132141,0,251.41218615),(0,205.751007,338.91119239),(0,0,1)))\n","\tdistortion = np.array(( 0.07640411,-0.06229856,0.01462332,0.0039293,0.00467759))\n","\n","\tdetected_markers=pose_estimation(img,cv2.aruco.DICT_4X4_50,intrinsic_camera,distortion)\n","\t# corners,ids,rejected=cv2.aruco.detectMarkers(img,arucoDict,parameters=arucoParams)\n","\t# detected_markers=aruco_display(corners,ids,rejected,img)\n","\tcv2.imshow(\"Image\",detected_markers)\n","\n","\tkey=cv2.waitKey(1)\n","\n","\tif key == 27:\n","\t\tbreak\n","cv2.destroyAllWindows()\n","cap.release()"]}]}